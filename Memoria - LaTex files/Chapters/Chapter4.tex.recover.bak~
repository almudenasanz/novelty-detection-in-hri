% Chapter 4

\chapter{Experiments} % Main chapter title

\label{Chapter4} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 4. \emph{Experiments}} % This is for the header on each page - perhaps a shortened title

This chapter describes the experiments carried out to evaluate the proposed solution. 
 
\section{Poses dataset, a dataset generated by Gonz√°lez-Pacheco et al. \cite{Gonzalez-Pacheco2013}}

The data provided for the evaluation of the system comes from another experiment developed in the Department of Automation and Systems Engineering at Universidad Carlos III de Madrid in the field of gesture and pose recognition. It consisted of 24 users who taught the robot a predetermined set of poses using a Microsoft Kinect camera \cite{Gonzalez-Pacheco2013}, the data retrieved was then labeled by the user trough a voice interaction with the user. Figure 4.1 shows the disposition of the experiment. It consisted of a Kinect camera placed inside the Social Robot Maggie, in the figure the cone represents the field of view of the Kinect sensor. The user was allowed to move inside the rectangle. \cite{Gonzalez-Pacheco2013}

The data retrieved from the user is a set of parameters that represent the 3D position of 15 joints of a human skeleton. The disposition of the data is showed in Figure 4.2.


\begin{figure}[h]
\includegraphics[width=8cm]{Figures/Scenario}
\centering
\caption{Scenario of the experiment. Retrieved from \cite{Gonzalez-Pacheco2013}}
\end{figure}

\begin{figure}[h]
\includegraphics[width=8cm]{Figures/Skeleton}
\centering
\caption{Kinematic of the human body. Retrieved from \cite{Gonzalez-Pacheco2013}}
\end{figure}

The entries forming the dataset have the following shape:
 
$S = (t,u,J)$, $J = (j1,j2,...,j15)$, $ji = (x,y,z,qx,qy,qz,qw,C)$

Being $t$ the time stamp, $u$ the user ID and $J$ the set of joints. Each set of joints is formed by 15 joints, and each of the joints is formed by x,y,z 3D positions, qx,qy,qz,qw, orientations and a confidence C.

These entries were preprocessed, as explained in Section 4.2.

The experiment was subdivided in 3 sets of poses taught to the robot:

- \textbf{Set 1} consisted of teaching the robot if the trainer was turned to his/her own left, right or if he/she was turned toward the robot.

- \textbf{Set 2}  consisted of teaching the robot if the trainer was looking to his/her own left, right or forward.

- \textbf{Set 3}  consisted of teaching the robot if the trainer was pointing at his/her own left, right or forward. 

\section{Data treatment for this experiment}

The data used for this Thesis was extracted from Set 3 of the experiment mentioned in Section 4.1, where users pointed right, left and forward. Picture (g) is an example of a user pointing LEFT, in (h) the user is pointing FORWARD and in (i) the user is pointing RIGHT.

\begin{figure}[h]
\includegraphics[width=10cm]{Figures/Set3}
\centering
\caption{Poses in Set 3 \cite{Gonzalez-Pacheco2013}}
\end{figure}

The user were not specified which arm they should use to pose. This to a variety of combinations of arms a positions for the same pose. In Figure 4.4 we can see examples of users posing. The color gray represent users posing forward, color blue represent users pointing left, and color green represent users pointing right. 

\begin{figure}[h]
\includegraphics[width=10cm]{Figures/Poses}
\centering
\caption{Examples of how different users pointed during the training for Set 3. retrieved form \cite{Gonzalez-Pacheco2013}}
\end{figure}

We can group the users posing in 3 classes: POINTING RIGHT, POINTING LEFT AND POINTING FORWARD. Within each class, there are different subclasses depending on the combinations of arms. In the tables in Appendix A all the combinations and the users that present them are exposed.

The first question presented is if this data can be simply linearly separable. Using Principal Component Analysis, all the examples were reduced to 2 dimensions and plotted, as can be seen in Figure 4.5. Red dots represent users pointing RIGHT, green dots represent users pointing FORWARD and blue dots represent users pointing LEFT.

\begin{figure}[h]
\includegraphics[width=10cm]{Figures/exp03}
\centering
\caption{2D reduction for Set 3 with original data}
\end{figure}

No correlation in the data can be extracted at first sight, but there should be some to perform this experiment. Observing the different skeleton shapes, we could see that the position of the legs was also very diverse. Because of the location of the Kinect camera, the legs in some users could not be recorded properly. Using a One-Class SVM outlier detection, we could confirm that the outliers detected furthest form the frontier were those with legs not recorded properly. Also, the center of the torso of the users was not always recorded at the position (0,0,0), as can be seen in figure 4.7.

\begin{figure}[h]
\includegraphics[width=4cm]{Figures/origin_poses}
\centering
\caption{Original data not referenced to (0,0,0)}
\end{figure}

Since we are interested in finding differences in the data, this could lead to the data being very different because of the legs or because of the reference of the torso. Those are not the differences we are interested in, we want the data to be different because it represents pointing each of the three poses. 

Thus, we need all of the poses to have the same reference origin. To accomplish this, the torso was moved to the point (0,0,0) and  all the other joints were normalized with respect to the torso. Figure 4.8 shows the skeletons shape after the normalization.

\begin{figure}[h]
\includegraphics[width=4cm]{Figures/origin_poses_mod}
\centering
\caption{Original data with torso referenced to (0,0,0)}
\end{figure}

Since the parts of the body that determine where the user is pointing are the torso and the arms, we decided to get rid of the legs and hips data points for each user. 

Figure 4.8 shows the PCA reduction after the modification of the data. Again red dots represent users pointing RIGHT, green dots represent users pointing FORWARD and blue dots represent users pointing LEFT.

\begin{figure}[h]
\includegraphics[width=10cm]{Figures/exp03_centered}
\centering
\caption{2D reduction for Set 3 with modified data}
\end{figure}

We can now see that the data is more correlated. But still we cannot separate each of the 3 types of poses linearly. The areas of interest, where the problems may appear, are those where two or more poses merge. Anyway, the correlation we see is a sign that the classes do exist and can be detected and differentiated.

The final dataset used for the experiments has the following parameters:

Size: 29 users
Dimensionality: 81 parameters

Our system will not have all this data as a start. The experiment consists on showing the system this examples one by one. The system will be able to detect if they belong to different classes by itself, and it will learn those new classes. 

\section{Method}

The data with the poses was provided in .arff files. Each file consisted of the set of skeletons produced by one user in a session of the experiment mentioned in Section 4.1. This files contained around a hundred rows of data, the number of rows of data was different for each user, and it depended on the time that user was recorded. The columns of the data corresponded to the position of the joints, each had a x, y, z and a confidence column. Other columns corresponded to the user-id, the h-seqNum and the h-stamp. The last column corresponded to the label of that pose, being STAND-POINTING-RIGHT, STAND-POINTING-LEFT and STAND-POINTING-FORWARD. The total number of columns was 124.

After the treatment of the data, all the non relevant columns were deleted. These include the label, user-id, h-seqNum, h-stamp and all columns corresponding to the position of feet, knees, and hips. The final entries had 81 columns. 

The data is divided by user and by pose. Each piece of data will consist of a user pointing in one of the three directions.

The Machine Learning algorithms used in the Thesis, One class SVM, K means and GMM come from the Scikit Lean \cite{scikit-learn} Python API. The only algorithms not contained in this API was Least Squares Anomaly Detection (LSA), that was developed by Jonh Quinn \cite{lsa}, the python file can be found in his webpage.

The experiments were done with Python programming in a IPython notebook. The representation of the data was done using the python library Matplotlib. Other python libraries used for the treatment of the data were Pandas and Numpy.

\section{Results}

The system had to be tested with different experiments to prove the resolution of the different objectives fo the Thesis. Firstly, we had to test that the system will recognize a new pose as interesting when it has seen something similar frequently. Secondly, we has to test the performance of the different algorithms to recognize strange entries in the data. A graphic interface was created to show the results of the tests and the shape of the skeletons we were considering, it can be seen in Figure 4.9.

The algorithms used for the experiments are One class SVM, LSA, K means and GMM. One class SVM and LSA provide directly a label that classifies the entries as strange or normal, and we have translated this labels to the numerical system as 1:strange or noise and 0:normal or interesting. K means and GMM provide a score, calculated as explained in Sections 3.1 and 3.2, when the score is lower than 1, the entry is classified as normal or interesting, depending of the test, and when it is higher than 1 it is classified as strange or noise.  

\subsection{Interestingness detection}

Figure 4.9 shows how the test for detecting interesting entries is showed to the user. In the example in the figure, a base of knowledge of POINTING RIGHT entries was taught to the system. We are trying to figure out when a new entry of POINTING LEFT will be considered interesting.

\begin{figure}[h]
\includegraphics[width=12cm]{Figures/results_imp/right_vs_left1}
\includegraphics[width=12cm]{Figures/results_imp/right_vs_left2}
\includegraphics[width=12cm]{Figures/results_imp/right_vs_left3}
\centering
\caption{Graphic interface showing, in the right side, the interestingness test of new POINTING LEFT entries with a base of knowledge of POINTING RIGHT entries}
\end{figure}

In all of the rows we can see the interestingness test on the right side, the 3D plot corresponds with the representation of the 3D data of the skeletons. The interestingness score is plotted next to it. All of the entries added to the system accumulate to calculate the interestingness score. On the left side, we can see the strangeness score, where we only test the entries against the normal learned entries by the system, the POINTING RIGHT entries. Unless a the tested new entry is detected as interesting, it won't pass to the second strangeness test.

The system will recognize a new pose as interesting when we show it similar entries with a minimum frequency. In the case of Figure 4.9, the frequency needed to detect the pose as interesting is 2. The third time a pose is showed to the system, it is considered interesting, and will pass to the second test that in this case is considered as strange. 

The following graph, in Figure 4.10, shows the general performance for the interestingness detection. The graph shows the evolution of the interestingness score for the different algorithms. The X axis represents how many users with the same pose have been showed to the system. A point below the threshold line, corresponding to the value 1, is telling us that the entry is detected as interesting. We consider that, al least, for the first user with a new pose showed to the system, the system should detect it as noise and not pay attention to it. This means that the score should be higher than 1.

\begin{figure}[h]
\includegraphics[width=14cm]{Figures/results_imp/Chart}
\centering
\caption{Interestingness score evolution when adding from 1 to 5 users of an unknown class to the system. Comparison of the different algorithms. Points below the threshold line indicate that the user is considered interesting }
\end{figure}

We can see that both GMM and K means consider the new pose as noise when it has been showed only once and twice to the system. When it is showed a third time, the algorithms detect that it is now interesting. The data obtained was averaged from 63 tests, with different pose combinations. 

One class SVM  also shows a significant decrease in the score when the third user is showed. The mean of the scores for the first user is 0.89. This indicates that, in a 11 $\%$ of the cases, the first user showed to the system was detected as interesting already, as thus, our One Class SVM filter failed.

LSA does not show a very good performance with this analysis, it misses 62 $\%$ of the cases when the new pose is presented the first time. 


Table 4.1 shows the data plotted in Figure 4.10.

\begin{table}[!ht]
	\footnotesize
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{cccccc}
	\hline 
	 & 1 user    &  2 users &  3 users & 4 users    &  5 users \\
	\hline
	GMM  & 4.36$\pm$0.7  & 1.42$\pm$0.3 & 0.35$\pm$0.07 & 0.15$\pm$0.02 & 0.006$\pm$0.01\\
	K means  & 5.1$\pm$1.2 & 1.42$\pm$0.25 & 0.56$\pm$0.10 & 0.38$\pm$0.06 & 0.32$\pm$0.06    \\
	One class SVM  & 0.89$\pm$0.07 & 0.77$\pm$0.10 & 0.28$\pm$0.10 & 0.33$\pm$$\pm$0.11 & 0.39$\pm$0.12  \\
	LSA   & 0.38$\pm$0.01 & 0.11$\pm$0.07 & 0.0$\pm$0.0& 0.0$\pm$0.0& 0.0$\pm$0.0   \\
	\hline
	\end{tabular}
	\centering
	\caption{Data corresponding to the graph in Figure 4.10. Interestingness score evolution when showing from 1 to 5 users of an unknown class to the system. Comparison of the different algorithms. Kfactor.GMM = 3, Kfactor.Kmeans=1}
\end{table}

As a reminder, the scores obtained from One Class SVM and LSA are only 1 or 0, so the variance in their scores is less than for GMM and K means.

Since we can also modify the score obtained from GMM and K means, using the curiosity factor presented in Section 3.5, we could also modify the frequency needed for the entries to be interesting. Instead of being 2, as in this case,  we could increase it of decrease it. For this purpose, the curiosity factor should be calculated empirically for each application, and is out of the scope of the work in this Thesis.   

From the point of view of our analysis, the algorithms that perform best to detect the interestingness of a new entry are GMM and K means.

\subsection{Global novelties}

The second step for the system, after a new data was detected as interesting, was finding out if that data was known or it was a novelty. Global novelties are those detected between poses, we want to differentiate POINTING RIGHT from POINTING LEFT or FORWARD. To evalute the performance of the different algorithms for this task, different experiments were carried out with the existing dataset.

The dataset was separated by poses, STAND-POINTING-RIGHT, STAND-POINTING-LEFT and STAND-POINTING-FORWARD. Each user has an entry for each pose. 

Dataset:

Size: 29 users * 3 poses = 87 entries

Dimensionality: 81 parameters

The system was tested for each of the three poses. The experiment consisted on teaching the system one of the poses, creating a model with 10 random users of that pose. Then the system had to classify 5 entries of each of the other 2 poses, and 10 entries of that same pose. The expected result is that all the entries from different poses will be detected as novel, and all the entries from the same pose will be detected as known.

\begin{table}[h]
    \begin{tabular}{| l | l |}
    \hline
    Training (normal) & Testing (normal + novel) \\ \hline
    10 & 10+10 \\ \hline
    \end{tabular}
    \centering
    \caption{Benchmark of the dataset size for all of the experiments in global novelties}
\end{table}

This test was carried out 10 times per pose. Tables 4.3, 4.4 and 4.5 show the results obtained for the different poses. Table 4.3 corresponds with a base of knowledge of POINTING RIGHT, 4.4 with POINTING LEFT and 4.5 with POINTING FORWARD.

The parameters used to measure the performance were given in terms of Binary classification. The binary classification calculates different parameters in terms of test outcomes for the entries. If the test is positive (1) the entry is classified as an novelty, if it is negative (0) it is classified as known.

Imagine we get a new data $y1$. We know that $y1$ is really a novelty, so $y1 = 1$. Knowing this, we test it with the system and retrieve an novelty classification prediction. The prediction is labeled as $y1'$.

If our system predices: 
\begin{equation}
\begin{split}
y1' = 1 \mbox{, we obtain a True Positive (TP)} \\
y1' = 0\mbox{, we obtain a False Negative (FN)}
\end{split}
\end{equation}

Now we get a new data, that we know it's not novel, $y2 = 0$, and test it with the system. The prediction of the system is now labeled as $y2'$.

\begin{equation}
\begin{split}
y2' = 0\mbox{, we obtain a True Negative (TN)} \\
y2' = 1\mbox{, we obtain a False Positive (FP)} 
\end{split}
\end{equation}

The following metrics were used to evaluate the performance of the algorithms:

\begin{description}
\item[]

\begin{equation}
Precision = \dfrac{TP}{ TP + FP}
\end{equation}

\item[]

\begin{equation}
Recall = \dfrac{TP}{TP + FN}
\end{equation}

\item[]

\begin{equation}
F score = \dfrac{2 x TP}{2xTP+FN+FP}
\end{equation}

\item[]

\begin{equation}
Accuracy = \dfrac{TP + TN}{TP + TN + FP + FN}
\end{equation}

\end{description}

The following tables summarize the performance of the algorithms for the different poses and with the mentioned metrics.

\begin{table}[!ht]
	\footnotesize
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{p{1.2cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}}
	\hline 
	 & \multicolumn{3}{c}{GMM}& \multicolumn{3}{c}{One class SVM}& \multicolumn{3}{c}{LSA}& \multicolumn{3}{c}{K means} \\
	 & Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE \\
	\hline
	Precision  & 0.87 & 0.03 & 0.01 & 0.81 & 0.06 & 0.02 & 0.89 & 0.07 & 0.02 & 0.91 & 0.06 & 0.02      \\
	Recall  & 0.88 & 0.13 & 0.04 & 0.94 & 0.09 & 0.03 & 0.87 & 0.12 & 0.04 & 0.75 & 0.13 & 0.04    \\
	F score  & 0.87 & 0.07 & 0.02 & 0.87 & 0.06 & 0.02 & 0.87 & 0.05 & 0.02 & 0.81 & 0.08 & 0.03    \\ 
	Accuracy   & 0.88 & 0.06 & 0.02 & 0.85 & 0.06 & 0.02 & 0.87 & 0.04 & 0.01 & 0.83 & 0.06 & 0.02   \\
	\hline
	\end{tabular}
	\centering
	\caption{Novelty Detection performance of the different algorithms when detecting a new entry with a base of knowledge of POINTING RIGHT entries. Kfactor.GMM = 3, Kfactor.Kmeans=1. Note: SD = Standard Deviation, SE = Standard Error  }
\end{table}

For POINTING RIGHT, the performance of all algorithms is similar. Achieving a 87 $\%$ of F score for GMM, LSA and One Class SVM, and a 80 $\%$ for K means. We cannot highlight a concrete algorithm, since each one has its own pros and cons. For example, if we are interested in having a low recall rate, so we don't bother the user with false alarms, the most appropriate would be One class SVM. On the other hand, if we are interested in precision and don't worry about bothering the user too much, the most precise algorithm would be K means.   

\begin{table}[!ht]
	\footnotesize
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{p{1.2cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}}
	\hline
	 & \multicolumn{3}{c}{GMM}& \multicolumn{3}{c}{One class SVM}& \multicolumn{3}{c}{LSA}& \multicolumn{3}{c}{K means} \\
	 & Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE \\
	\hline
	Precision  & 0.72 & 0.10 & 0.03 & 0.70 & 0.06 & 0.02 & 0.77 & 0.40 & 0.13 & 0.69 & 0.34 & 0.11      \\
	Recall  & 0.94 & 0.13 & 0.04 & 0.74 & 0.14 & 0.05 & 0.16 & 0.17 & 0.06 & 0.15 & 0.07 & 0.02    \\
	F score  & 0.80 & 0.04 & 0.01 & 0.72 & 0.09 & 0.03 & 0.24 & 0.21 & 0.07 & 0.24 & 0.10 & 0.03    \\
	Accuracy   & 0.77 & 0.04 & 0.01 & 0.72 & 0.08 & 0.03 & 0.57 & 0.08 & 0.03 & 0.54 & 0.05 & 0.02   \\
	\hline
	\end{tabular}
	\centering
	\caption{Novelty Detection performance of the different algorithms when detecting a new entry with a base of knowledge of POINTING LEFT entries. Kfactor.GMM = 3, Kfactor.Kmeans=1. Note: SD = Standard Deviation, SE = Standard Error  }
\end{table}

For POINTING LEFT the F score performance of all algorithms lowers with respect to POINTING right, this is specially critical for LSA ans K means. It is important to take into account that POINTING LEFT has many variants within the class, that can be seen in Appendix A. This may lead to have sub classes that differ a lot from each other. We will try to address this problem in Section 4.4.3, when detecting In-class novelties.

\begin{table}[!ht]
	\footnotesize
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{p{1.2cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}}
	\hline
	 & \multicolumn{3}{c}{GMM}& \multicolumn{3}{c}{One class SVM}& \multicolumn{3}{c}{LSA}& \multicolumn{3}{c}{K means} \\
	 & Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE \\
	\hline
	Precision  & 0.86 & 0.08 & 0.03 & 0.84 & 0.10 & 0.03 & 0.91 & 0.11 & 0.04 & 0.32 & 0.40 & 0.13       \\
	Recall  &  0.96 & 0.07 & 0.02 & 0.77 & 0.19 & 0.06 & 0.37 & 0.17 & 0.06 & 0.15 & 0.19 & 0.06    \\
	F score  & 0.90 & 0.04 & 0.01 & 0.78 & 0.12 & 0.04 & 0.50 & 0.17 & 0.06 & 0.20 & 0.26 & 0.09     \\
	Accuracy   & 0.89 & 0.05 & 0.02 & 0.80 & 0.07 & 0.02 & 0.66 & 0.08 & 0.03 & 0.55 & 0.08 & 0.03   \\
	\hline
	\end{tabular}
	\centering
	\caption{Novelty Detection performance of the different algorithms when detecting a new entry with a base of knowledge of POINTING FORWARD entries. Kfactor.GMM = 3, Kfactor.Kmeans=1. Note: SD = Standard Deviation, SE = Standard Error  }
\end{table}

The test with POINTING FORWARD led to the best F score performance with GMM. On the contrary, the worst F score was achieved with K means. POINTING FORWARD also contains In class variants that may affect to the result achieved, and will be studied in Section 4.4.3.

We will now test how the size of the base of knowledge affects this metrics. We will use the class POINTING RIGHT as the base of knowledge because its performance was moderately for all the algorithms.

\begin{table}[!ht]
	\footnotesize
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{p{1.2cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}}
	\hline 
	 & \multicolumn{3}{c}{GMM}& \multicolumn{3}{c}{One class SVM}& \multicolumn{3}{c}{LSA}& \multicolumn{3}{c}{K means} \\
	Size  & Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE \\
	\hline
	5  & 0.80 & 0.01 & 0.00 & 0.86 & 0.06 & 0.02 & 0.57 & 0.33 & 0.11 & 0.86 & 0.09 & 0.03      \\
	10  & 0.87 & 0.07 & 0.02 & 0.87 & 0.06 & 0.02 & 0.87 & 0.05 & 0.02 & 0.81 & 0.08 & 0.03    \\
	20 (a)  & 0.00 & 0.00 & 0.00 & 0.93 & 0.05 & 0.02 & 0.89 & 0.08 & 0.03 & 0.79 & 0.05 & 0.02    \\ 
	20 (b)   & 0.88 & 0.09 & 0.03 & 0.92 & 0.07 & 0.02 & 0.90 & 0.07 & 0.02 & 0.80 & 0.09 & 0.03   \\
	\hline
	\end{tabular}
	\centering
	\caption{F1 parameter performance of the different algorithms when detecting a new entry with a base of knowledge of POINTING RIGHT entries with different sizes of the base of knowledge. All trials: Kfactor.Kmeans = 1. (5) Kfactor.GMM = 30, (10) Kfactor.GMM = 3, (20(a)) Kfactor.GMM = 3, (20(b)) Kfactor.GMM = 0.1  Note: Size = number of users in the base of knowledge, SD = Standard Deviation, SE = Standard Error}
\end{table}

The Kfactor.GMM had to be modified depending on the size of the base of knowledge. For the last trial, the one with 20 users as the base of knowledge, because with the previous Kfactor all entries were detected as normal. For the first one, it had to be increased to 30, since none of the entries were detected as normal. The Kfactor.Kmeans, on the other hand, was suitable for all fo the trials. This relies on the calculation of the algorithm score provided by the Scikit Learn API.

We can observe that the F score performance of GMM, One class SVM and LSA all increase with the expansion of the base of knowledge, they perform better the bigger the base of knowledge is. On the other hand, K means performs better the smaller the base of knowledge is. This relies too on the mathematical methods used by the different algorithms.  

\subsection{In-class novelties}

As a lower performance rate can be observed for some algorithms when tested with the classes POINTING LEFT and POINTING FORWARD, we decided to test this classes more specifically. We divided the poses of this classes in sub-classes. The aim is to test if the system would detect if the user is pointing left with his/her right arm or with his/her left arm. The sub-classifications of the data are displayed in Appendix A.

The following tests have a base of knowledge of 5 users, and are tested with 6 instances belonging to the same sub-class, and with 2 instances belonging to the same class and a different sub class and 4 instances belonging to a different class. The predicted result is that instances belonging to the same sub class will be detected as normal, and those belonging to a different sub class or a different class will be detected as novel.  

\begin{table}[h]
    \begin{tabular}{| l | l |}
    \hline
    Training (normal) & Testing (normal + anomaly) \\ \hline
    5 & 6+6 \\ \hline
    \end{tabular}
    \centering
    \caption{Benchmark of the dataset size for all of the experiments in in-class novelties}
\end{table}

The following tables summarize the performance of the algorithms for the different poses and with the mentioned metrics.

\begin{table}[!ht]
	\footnotesize
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{p{1.2cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}}
	\hline 
	 & \multicolumn{3}{c}{GMM}& \multicolumn{3}{c}{One class SVM}& \multicolumn{3}{c}{LSA}& \multicolumn{3}{c}{K means} \\
	 & Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE \\
	\hline
	Precision  & 0.90 & 0.12 & 0.04 & 0.63 & 0.10 & 0.03 & 0.95 & 0.11 & 0.04 & 0.73 & 0.14 & 0.05       \\
	Recall  & 0.95 & 0.08 & 0.03 & 1.00 & 0.00 & 0.00 & 0.95 & 0.08 & 0.03 & 1.00 & 0.00 & 0.00    \\
	F score  & 0.92 & 0.07 & 0.02 & 0.77 & 0.08 & 0.03 & 0.95 & 0.07 & 0.02 & 0.84 & 0.09 & 0.03    \\
	Accuracy   & 0.91 & 0.08 & 0.03 & 0.69 & 0.12 & 0.04 & 0.94 & 0.08 & 0.03 & 0.79 & 0.14 & 0.05   \\
	\hline
	\end{tabular}
	\centering
	\caption{Detection performance of the different algorithms when detecting a new entry with a base of knowledge of POINTING LEFT, Pointing hand LEFT other hand HANGING  entries. Kfactor.GMM = 30, Kfactor.Kmeans=1 .Note: SD = Standard Deviation, SE = Standard Error}
\end{table}

The performance for the in-class novelty detection increases significantly, specially for LSA and Kmeans. The F score for LSA goes from a 24 $\%$ to a 95 $\%$ and for K means from a  24 $\%$ to a 84 $\%$. In GMM and One Class SVM we can also see an increase, but not so significant.

This shows that, in fact, in class novelties are relevant and affect the performance of the system. 

In Tables 4.9 and 4.10, we prove that this is not an isolated event. In Table 4.9 we train the system with another sub class withing the POINTING LEFT class, and the performance also increases with respect to the general POINTING left performance presented in the previous Section.

\begin{table}[!ht]
	\footnotesize
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{p{1.2cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}}
	\hline 
	 & \multicolumn{3}{c}{GMM}& \multicolumn{3}{c}{One class SVM}& \multicolumn{3}{c}{LSA}& \multicolumn{3}{c}{K means} \\
	 & Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE \\
	\hline
	Precision  & 0.62 & 0.14 & 0.05 & 0.58 & 0.08 & 0.03 & 0.78 & 0.39 & 0.13 & 0.86 & 0.18 & 0.06       \\
	Recall  & 0.92 & 0.11 & 0.04 & 0.95 & 0.08 & 0.03 & 0.22 & 0.15 & 0.05 & 0.52 & 0.19 & 0.06    \\
	F score  & 0.73 & 0.08 & 0.03 & 0.72 & 0.07 & 0.02 & 0.32 & 0.20 & 0.07 & 0.62 & 0.16 & 0.05    \\
	Accuracy   & 0.64 & 0.12 & 0.04 & 0.62 & 0.12 & 0.04 & 0.60 & 0.06 & 0.02 & 0.71 & 0.10 & 0.03   \\
	\hline
	\end{tabular}
	\centering
	\caption{Detection performance of the different algorithms when detecting a new entry with a base of knowledge of POINTING LEFT, Pointing hand RIGHT other hand HANGING  entries. Kfactor.GMM = 30, Kfactor. Kmeans=1.Note: SD = Standard Deviation, SE = Standard Error}
\end{table}

This also applies to in-class novelties within the POINTING FORWARD class, as Table 4.10 shows. The F score for LSA goes from a 50 $\%$ to a 58 $\%$ and for K means from a  20 $\%$ to a 54 $\%$. In One Class SVM we can also see an increase, but not so significant. However, the GMM algorithm still outperforms the other three and its performance is lower than when the system was trained with different sub-classes in Table 4.5.

\begin{table}[!ht]
	\footnotesize
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{p{1.2cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}}
	\hline 
	 & \multicolumn{3}{c}{GMM}& \multicolumn{3}{c}{One class SVM}& \multicolumn{3}{c}{LSA}& \multicolumn{3}{c}{K means} \\
	 & Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE& Mean    & SD & SE \\
	\hline
	Precision  & 0.67 & 0.13 & 0.04 & 0.57 & 0.09 & 0.03 & 0.79 & 0.30 & 0.10 & 0.60 & 0.25 & 0.08       \\
	Recall  & 0.80 & 0.18 & 0.06 & 0.88 & 0.15 & 0.05 & 0.50 & 0.25 & 0.08 & 0.53 & 0.27 & 0.09    \\
	F score  & 0.71 & 0.13 & 0.04 & 0.69 & 0.10 & 0.03 & 0.58 & 0.23 & 0.08 & 0.54 & 0.22 & 0.07    \\
	Accuracy   & 0.68 & 0.15 & 0.05 & 0.60 & 0.12 & 0.04 & 0.69 & 0.11 & 0.04 & 0.62 & 0.11 & 0.04   \\
	\hline
	\end{tabular}
	\centering
	\caption{Detection performance of the different algorithms when detecting a new entry with a base of knowledge of POINTING FORWARD, Pointing hand RIGHT other hand HANGING  entries. Kfactor.GMM = 30, Kfactor. Kmeans=1. Note: SD = Standard Deviation, SE = Standard Error}
\end{table}

\subsection{Novelties in multi-class systems}

As one of the objectives in the Thesis if that the system learns continuously, at some point the system may have learned POINTING RIGHT and POINTING FORWARD and the new entry corresponds to a new class POINTING LEFT. The following tests show the performance of the system when faced with this problem of knowing two classes and being asked to classify a third.

\begin{figure}[h]
\includegraphics[width=14cm]{Figures/results_two/two_classes}
\centering
\caption{Graphic interface showing, in the right side, the interestingness test of new POINTING LEFT entries with a base of knowledge of POINTING RIGHT and POINTING FORWARD entries }
\end{figure}

\begin{table}[!ht]
	\footnotesize
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{p{1.2cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.7cm}}
	\hline 
	 & \multicolumn{3}{c}{GMM}& \multicolumn{3}{c}{One class SVM}& \multicolumn{3}{c}{LSA}& \multicolumn{3}{c}{K means} \\
	New class  & Mean & SD & SE& Mean & SD & SE& Mean & SD & SE& Mean & SD & SE \\
	\hline
	RIGHT  & 0.67 & 0.19 & 0.10 & 0.79 & 0.07 & 0.03 & 0.70 & 0.18 & 0.09 & 0.84 & 0.06 & 0.03      \\
	LEFT  & 0.68 & 0.02 & 0.01 & 0.82 & 0.03 & 0.02 & 0.60 & 0.05 & 0.03 & 0.69 & 0.13 & 0.06    \\
	FORWA.  & 0.78 & 0.07 & 0.03 & 0.74 & 0.10 & 0.05 & 0.53 & 0.17 & 0.09 & 0.67 & 0.05 & 0.03    \\  
	\hline
	\end{tabular}
	\centering
	\caption{F1 parameter performance of the different algorithms when detecting a new entry of the 'New class' with a base of knowledge of the other two classes. Kfactor.Kmeans = 1 Kfactor.GMM = 0.8  Note: New class = new class presented to the system, SD = Standard Deviation, SE = Standard Error}
\end{table}


\section{Discussion}

The presented results show that it is possible to build a system that distinguishes when new poses are interesting and strange. An thus, the system does not pay attention when unusual poses happen once, but it becomes curious when an unusual pose happens several times, and it can't recognize it. 

We have proven that our current systems does not detect an entry as interesting until similar entries have appeared twice before. This filters out noisy entries that may appear, and the system will not bother the user asking too many times. As seen in the performance graph, the algorithms that work best from our approach are GMM and K means.

The results also show that the system is able to distinguish between known data and novel data. Nevertheless, we have seen that the performance of the system depends highly on the pose we train the system with. The worst performance was achieved when we trained the system with random users from the POINTING LEFT class. We later saw that the POINTING LEFT class could be divided in sub classes, and the performance of the algorithms increased greatly when the system was trained with this sub classes separately.

For GMM, One class SVM and LSA, the performance of the algorithms increased when we increased the size of the base of knowledge, meaning that we trained the system with more instances of the normal pose. However, the performance of K means lowered. Thus, for future applications, when we start the learning process and we only have access to a small number of training instances, K means would perform better. But as the systems learns and increases the size the base of knowledge, we may want to switch and use one of the other three algorithms.

We also saw that it is possible to learn continuously and keep operating. This means to train the algorithm with two poses and detect a third one as novel. This is called multi-class novelty detection. However, the general performance of the algorithms lowered in this test, and other multi-class algorithms should be taken into consideration to improve this performance in future work.  

We must stress that this was not a trivial problem to work with. The datasets used, as displayed in Appendix A, included many variations within the poses, and some of them were very similar without belonging to the same class, see POINTING FORWARD with the right hand and POINTING LEFT with the right hand. The differences for most os the users was very slight. 

To conclude, we can see this results as a proof of concept. They show that it is possible to build a continuous learning framework, where the robot actively seeks for new examples and asks questions to its teacher about the concepts being learned. This Thesis has not dealt with asking questions about the data, since that would be more specific to an application. But our system knows WHEN to ask questions about it. It opens the door to future applications in different fields, and this method and system can be extrapolated to other learning problems inside or outside pose recognition. It is specially relevant in Human-Machine interaction, since our system breaks down the steps of the curiosity process in human behavior.   


%----------------------------------------------------------------------------------------